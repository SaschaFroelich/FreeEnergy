{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An intuitive Understanding of Free Energy in Statistical Physics\n",
    "## Introduction\n",
    "\n",
    "This article will give an intuitive review of the Free Energy as it is defined in statistical physics. We will see that Free Energy is a measure of a system's capacity to do work and that its minimization is a statistical necessity for a closed system. For the sake of clarity, I will use examples and interpretations which are not physically rigorous but help to develop a good understanding of the matter.\n",
    "\n",
    "The toy example we are looking at is a two-state system which consists of ten \"particles\" which can take on two discrete energy values $E_0 = 0 J$ and $E_1 = 1 J$. A real-world analogon might be a collection electrons inside a magnetic field. Electrons whose spins are aligned parallel to the field correspond to particles in the lower energy level, while electrons with spins antiparallel to the field lines reside on the higher energy level (see Fig 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A two-level system with energy $E=6J$](./figures/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now consider one such system whose total energy is known to be $6J$. This means that six of its particles reside on the upper energy level while four particles occupy the lower level. One such possible system is shown in Figure 1. The committed reader may now pause for a second and consider for themselves if the displayed system appears to be in equilibrium or not. The (hopefully intuitive) answer is no. While we did not yet consider what \"equilibrium\" actually means, it may feel intuitive that in the given case, it means that the excited particles at energy $1J$ and the particles at energy $0J$ are somehow evenly distributed and do not clump together in one small region of the system.\n",
    "\n",
    "In our case of of a 10-particle system with energy of $6J$, the number of possible microstates is \n",
    "\n",
    "$$\\Omega_0(E = 6J) = {10\\choose 6} = \\frac{10!}{6!\\cdot 4!} = 210.$$\n",
    "\n",
    "In order to understand the main point of this article, we will apply a little trick whose use will become apparent later. We will split the system of ten particles into two compartments of five particles, the left of which we will call System A, while the other is System B (Fig. 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![We separate the total system into two subsystems](./figures/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next, we will go on to find the __most likely__ energy configurations of systems $A$ and $B$ such that their total energy $E = E_A + E_B$ equals $6 J$. We will find that the most probable energy configuration is the homogeneous state $E_A = E_B = 3J$ and that this state is reached by minimization of free energy or, equivalently, maximization of entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Probability for a given Energy of System A\n",
    "\n",
    "The question we are now trying to anser is:\n",
    "<br>\n",
    "<br>\n",
    "For a system composed of two systems $A$ and $B$ as above, with total energy $E$, how likely is System $A$ to assume a specific energy level $E_A$?\n",
    "\n",
    "In order to do this, we have to rely on one of the great postulates of statistical physics which we will accept as given (see Bibliography):\n",
    "<br>\n",
    "<br>\n",
    "POSTULATE: In the equilibrium state, all possible microstates of a system are equally likely.\n",
    "<br>\n",
    "<br>\n",
    "This postulate is also known as the __The Fundamental Assumption of Statistical Mechanics__.\n",
    "Using this postulate, our original question can be cast into mathematical form for the probability of System $A$ to have energy $E_A$. This is equal to the ratio of microstates that realize that energy to all other possible microstates that would result in a total energy of $E = 6J$:\n",
    "\n",
    "$$W(E_A) \\equiv (\\text{Probability of System A assuming energy level }E_A) = \\frac{\\Omega_A(E_A)\\cdot \\Omega_B(E_B = E -E_A)}{\\Omega_0(E)} \\text{     (Eq. 1)}.$$\n",
    "\n",
    "As this formula might feel intimidating for the mathematical layperson, I will go through it step by step:\n",
    "$\\Omega(E_A)$ is the number of microstates of System A that would realize a specific energy $E_A$. For our example (Figure 1), that energy corresponds to one particle in System A sitting on the upper energy level, thus $E_A = 1J$. For a total of 5 particles in System A, this is true for 5 different microstates, therefore $\\Omega(E_A) = 5$. As we started with a known total energy $E = E_A + E_B$ (in our example 6J), requiring $E_A$ to be equal to $1J$ determines System B's energy $E_B = 5J$. The number of microstates that realize this is $\\Omega(E_B = 5J) = 1$, as all particles in System B have to be in the upper state. The total number of different configurations such that $E_A$ is assumed by System A and $E_B$ by System B is therefore the product of the number of different microstates $\\Omega_A(E_A)$ and $\\Omega_B(E_B)$. The probability that any of these configurations is assumed is then equal to the ratio of that product with the number of all other possible microstates $\\Omega_0(E)$ such that the total energy is $E$. In our case of 10 particles, six of which have to be in the upper energy level, that number is 210, as seen above. Therefore, the probability of finding our energy configuration in Figure 1 for a system at equilibrium is\n",
    "\n",
    "$$W(E_A = 1J) = \\frac{\\Omega_A(E_A = 1 J)\\cdot \\Omega_B(E_B = 5J)}{\\Omega_0(E = 6J)} = \\frac{1\\cdot 1}{210} \\approx 0.005.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the most likely Energy for System A\n",
    "\n",
    "We are now interested in the most likely energy configuration for Systems $A$ and $B$ in the equilibrium state. The general idea is to find the value $\\bar{E_A}$, for which $W(E_A)$ assumes a maximum value. This value can be found by setting the derivative of the probability function $W(E_A)$ to zero.\n",
    "\n",
    "$$\\frac{d}{d E_A} \\ln (W(E_A)) = 0$$\n",
    "\n",
    "The fact that we are deriving $\\ln W(E_A)$ instead of $W(E_A)$ may not concern us here. The reason this is commonly done in statistical physics is that the maximum of the function $W(E_A)$ is at the same position as the maximum of the function $\\ln W(E_A)$, while the latter is mathematically easier to deal with than the former. \n",
    "\n",
    "The energy $\\bar{E_A}$ which maximizes $W(E_A)$ is then found to be the energy at which the energy is homogeneously dsitributed across the system:\n",
    "\n",
    "$$\\frac{\\bar{E_A}}{f_A} = \\frac{\\bar{E_B}}{f_B} (Eq. 2),$$\n",
    "\n",
    "where $f_i$ denotes the number of degrees of freedom of system i. In our example, the number of degrees of freedom is equal to the number of particles. What this means is that the most likely state a system at equilibrium will find itself in is a state of homogeneous energy distribution. This can be deduced from a purely statistical way of reasoning: The system at equilibrium can be found in each microstate with the same probability. The energy configuration the system will mos likely be found in is therefore the configuration which has the highest number of possible microstates. That energy configuration is however exactly the homogeneous case, where all imagined subsystem contain the same energy. More concretely, for our example:\n",
    "\n",
    "$E_A = 1J \\rightarrow \\Omega_A(E_A)\\cdot \\Omega_B(E_B) = 5$\n",
    "\n",
    "$E_A = 2J \\rightarrow \\Omega_A(E_A)\\cdot \\Omega_B(E_B) = 50$\n",
    "\n",
    "$E_A = 3J \\rightarrow \\Omega_A(E_A)\\cdot \\Omega_B(E_B) = 100$\n",
    "\n",
    "$E_A = 4J \\rightarrow \\Omega_A(E_A)\\cdot \\Omega_B(E_B) = 50$\n",
    "\n",
    "$E_A = 5J \\rightarrow \\Omega_A(E_A)\\cdot \\Omega_B(E_B) = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The probability for System A to have half of the total energy is highest](./figures/fig3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy is defined as \n",
    "\n",
    "$$S = k_B \\ln \\Omega(E).$$\n",
    "\n",
    "Furthermore, entropy is an extensive property, i.e. the entropy of an ensemble of subsystems is the sum of the entropies of the single systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, entropy is an extensive property, i.e. the entropy of an ensemble of subsystems is the sum of the entropies of the individual systems:\n",
    "\n",
    "$$\\Omega(E) = \\Omega_A(E_A)\\cdot \\Omega_A(E_A) \\rightarrow S = k_B \\ln \\Omega(E) = k_B \\ln \\left( \\Omega_A(E_A)\\cdot \\Omega_A(E_A) \\right) \\rightarrow S = S_A + S_B$$\n",
    "\n",
    "Via the relations between the energy configurations of the subsystems and the number of microstates which would realize such configuration, it is easily seen that the entropy in this example is maximized by the homogeneous distribution of energies where $S_A = S_B$.\n",
    "\n",
    "\n",
    "# Free Energy\n",
    "\n",
    "The (Helmholtz) Free Energy $F$ is defined as\n",
    "\n",
    "$$F = E -TS,$$\n",
    "\n",
    "where $E$ is the internal energy of the system and $T$ the (fixed) temperature of the system (equivalent to the system being in contact with a heat bath). As we have seen before, a closed system will always strive towards the equilibrium state which is equivalent to maximization of entropy. Given that $T$ is considered fixed, maximization of entropy thus corresponds to minimaztion of the free energy $F$. Note that the assumption of a given temperature $T$ is important here as otherwise $E$ and $T$ might be related via $$ \\frac{1}{T} = \\frac{dS}{dE}.$$\n",
    "\n",
    "\n",
    "# Physical interpretation and work\n",
    "\n",
    "The above example was rather mathematical without much emphasis on physical interpretation. However, the concept of minimization of free energy $F$ does also have a very elegant physical interpretation.\n",
    "\n",
    "As the minimum value of $F$ is reached when energy is homogeneously distributed across the system, a non-minimal value of $F$ is equivalent to local energy inhomogeneities. That is to say that the energy density varies from one point in the system to another. These changes in density can be described as energy gradients. Much like an electric potential is the necessary driver for flow of electric current, those energy gradients may create energy flows which, again, strive to reduce overall inhomogeneity. These energy flows can be harnessed to perform work. It is for this reason that free energy is generally considered as a measure of the energy with which a system can perform work. A system with high internal energy will not be able to perform work if that energy is completely homogeneously distributed.\n",
    "\n",
    "\n",
    "# Temperature\n",
    "\n",
    "A homogeneous distribution of energy has as a direct consequence that the system at hand has the same temperature everywhere. This can easily be seen considering the equipartition theorem which relates the mean energy of a system in equilibrium with its temperature. For an ideal gas, the mean energy per atom is:\n",
    "\n",
    "$$\\bar{E} = \\frac{3}{2}k_BT$$\n",
    "\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "Given the example considerations we can summarize the following:\n",
    "\n",
    "1) The increase of entropy (and thus the decrease of free energy) is a statistical necessity. It describes a closed system's tendency to approach an equilibrium distribution with a homogeneous distribution of energy.\n",
    "\n",
    "2) Free Energy is a measure of how far the system is from its equilibrium state. It is also a measure of the energy a system can harness to perform work.\n",
    "\n",
    "2) This minimization of free energy $F$ can be interpreted on a physically level, as follows. Because a non-maximum value of the entropy (and thus non-minimal value of the Free Energy) corresponds to an inhomogeneous distribution of energy, minimization of $F$ is equivalent to saying that the system contains energy gradients with spatial extension larger than any single constituent (particle, say) of the system. These energy gradients are natural drivers of energy exchange, thus energy flow. This flow of energy can be harnessed to do work and thus drive motion. Internal energy alone does not give any information of a system's capacity to do work, while the distribution of energy within the system (i.e. its free energy) does.\n",
    "\n",
    "4) By the above train of reasoning, the minimization of free energy corresponds to a well-known fact from biology: namely that every (living) system strives for homeostasis, i.e. internal equilibrium.\n",
    "\n",
    "\n",
    "# Bibliography\n",
    "\n",
    "Torsten Flie√übach: Statistische Physik IV\n",
    "\n",
    "\n",
    "# Suggested Further Reading\n",
    "\n",
    "[1] E.T. Jaynes: Gibbs vs Boltzmann Entropies, American Journal of Physics __33__, 391 (1965).\n",
    "\n",
    "Link: https://aapt.scitation.org/doi/pdf/10.1119/1.1971557?class=pdf\n",
    "\n",
    "[2] E.T. Jaynes: The Gibbs Paradox. Link: https://bayes.wustl.edu/etj/articles/gibbs.paradox.pdf\n",
    "\n",
    "\n",
    "# THE END\n",
    "\n",
    "\n",
    "# ============================================\n",
    "\n",
    "\n",
    "# ToDo \n",
    "\n",
    "\n",
    "5) In systems with a large number of degrees of freedom (any macroscopic system for that matter) the probability distribution for the system's energy distribution is extremely thin. Variance: ???\n",
    "\n",
    "6) Reaching same temperature\n",
    "\n",
    "- The width of the probability distro around the homogeneous situation is really small\n",
    "- meaning of \"equilibrium\": In thermodynamic equilibrium there are no net macroscopic flows of matter or of energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addendum\n",
    "\n",
    "This article is specifically meant as an intuitive introduction to the Free Energy as it is known in statistical physics. The attentive reader may however have noticed that the reasoning is somewhat circular, or better, not rigorous. This is because the Fundamental Assumption of Statistical Mechanics is formulated for the equilibrium state of a system. Using this assumption we showed that a homogeneous distribution of energy is the most likely energy configuration. This is, however, exactly the definition of a system at equilibrium. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
